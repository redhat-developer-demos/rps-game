{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8ba342a",
   "metadata": {},
   "source": [
    "## Yolo Rock Paper Scissors Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6589ba",
   "metadata": {},
   "source": [
    "### Dependencies and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b16a1bd-d10f-4a3c-bd7c-10a04808039d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Install required dependencies\n",
    "!pip install -q \"ultralytics<=8.3.40\" \"supervision==0.25.1\" \"roboflow==1.1.54\" \"opencv-python==4.11.0.86\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0043c6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import shutil\n",
    "import git\n",
    "from git import Repo, GitCommandError\n",
    "import requests\n",
    "from ultralytics import YOLO\n",
    "from roboflow import Roboflow\n",
    "from IPython.display import Image as IPyImage, display\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5fe934",
   "metadata": {},
   "source": [
    "### Download the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b8d1b6-ffc5-4698-a53a-5fb64cf76b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set home directory\n",
    "HOME = os.getcwd()\n",
    "print(f\"Current Working Directory: {HOME}\")\n",
    "\n",
    "# Create datasets and models folders\n",
    "dataset = os.path.join(HOME, \"datasets\")\n",
    "os.makedirs(dataset, exist_ok=True)\n",
    "\n",
    "models = os.path.join(HOME, \"models\")\n",
    "os.makedirs(models, exist_ok=True)\n",
    "\n",
    "# Define repository details\n",
    "repo_url = \"https://github.com/redhat-developer-demos/rps-game\"\n",
    "repo_path = os.path.join(HOME, \"rps-game\")\n",
    "branch = \"small-dataset\"\n",
    "\n",
    "# Function to clone or update the repository\n",
    "def clone_or_update_repo(repo_url, repo_path, branch):\n",
    "    if os.path.exists(repo_path):\n",
    "        try:\n",
    "            repo = Repo(repo_path)\n",
    "            if repo.bare:\n",
    "                print(\"Existing repository is bare. Removing and re-cloning...\")\n",
    "                shutil.rmtree(repo_path)\n",
    "                raise FileNotFoundError  # Trigger the cloning process\n",
    "            else:\n",
    "                print(f\"Repository already exists at {repo_path}. Attempting to fetch latest changes...\")\n",
    "                repo.git.checkout(branch)\n",
    "                repo.git.pull()\n",
    "                return repo_path\n",
    "        except (GitCommandError, FileNotFoundError):\n",
    "            print(f\"Error accessing existing repository. Removing and re-cloning...\")\n",
    "            shutil.rmtree(repo_path)\n",
    "    \n",
    "    # Clone the repository\n",
    "    print(f\"Cloning repository from {repo_url} into {repo_path}...\")\n",
    "    Repo.clone_from(repo_url, repo_path, branch=branch, depth=1)\n",
    "    print(\"Clone successful.\")\n",
    "    return repo_path\n",
    "\n",
    "# Clone or update the repository\n",
    "repo_path = clone_or_update_repo(repo_url, repo_path, branch)\n",
    "\n",
    "# Define the dataset source path\n",
    "data_source = os.path.join(repo_path, \"roshambo-notebooks\", \"data\")\n",
    "\n",
    "# Copy dataset folder if it exists\n",
    "if os.path.exists(data_source):\n",
    "    destination_path = os.path.join(dataset, \"data\")\n",
    "    shutil.copytree(data_source, destination_path, dirs_exist_ok=True)\n",
    "    print(f\"Dataset copied to {destination_path}\")\n",
    "else:\n",
    "    print(\"Dataset folder not found in repository.\")\n",
    "\n",
    "# Define full dataset path\n",
    "dataset_full_path = os.path.join(dataset, \"data\")\n",
    "print(f\"Full dataset path: {dataset_full_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d90442",
   "metadata": {},
   "source": [
    "### Download PreTrained YOLO Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32e7340",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd {HOME}\n",
    "\n",
    "# Download the Yolov11 Original Pretrained Model\n",
    "dataset_location = dataset\n",
    "url = \"https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11s.pt\"\n",
    "target_dir = dataset\n",
    "\n",
    "# Define the file path\n",
    "yolov11_orig_file_path = os.path.join(target_dir, os.path.basename(url))\n",
    "\n",
    "# Download the file\n",
    "response = requests.get(url, stream=True)\n",
    "if response.status_code == 200:\n",
    "    with open(yolov11_orig_file_path, \"wb\") as file:\n",
    "        for chunk in response.iter_content(chunk_size=1024):\n",
    "            file.write(chunk)\n",
    "    print(f\"Downloaded successfully: {yolov11_orig_file_path}\")\n",
    "else:\n",
    "    print(f\"Failed to download file, status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9c1c27",
   "metadata": {},
   "source": [
    "### Training new YOLO Model with Rock Paper Scissors Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0cf7b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = f\"{dataset_full_path}/data.yaml\"\n",
    "\n",
    "# Load the Yolov11 Original Pretrained Model\n",
    "model = YOLO(yolov11_orig_file_path)\n",
    "\n",
    "# Number of epochs to Train\n",
    "epochs = 1\n",
    "\n",
    "# Train the model\n",
    "results = model.train(\n",
    "    data=dataset_path,\n",
    "    epochs=epochs,\n",
    "    imgsz=640,\n",
    "    plots=True,\n",
    "    exist_ok=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b90be9f",
   "metadata": {},
   "source": [
    "### Check Model Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6f0927",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List trained model results\n",
    "#!ls {HOME}/runs/detect/train/\n",
    "\n",
    "# Display training results\n",
    "display(IPyImage(filename=f'{HOME}/runs/detect/train/confusion_matrix.png', width=600))\n",
    "display(IPyImage(filename=f'{HOME}/runs/detect/train/results.png', width=600))\n",
    "display(IPyImage(filename=f'{HOME}/runs/detect/train/val_batch0_pred.jpg', width=600))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fdc909e",
   "metadata": {},
   "source": [
    "### Copy new Trained Model to Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d6721a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Define paths\n",
    "train_location = f\"{HOME}/runs/detect/train/weights\"\n",
    "destination_dir = models  # Ensure dataset.location is valid\n",
    "\n",
    "# Define the models directory inside destination_dir\n",
    "models_dir = os.path.join(destination_dir, \"yolo\", \"1\")\n",
    "\n",
    "# Define new model name based on epochs\n",
    "# epochs = 1  # Ensure this variable is defined\n",
    "new_model_name = f\"yolo-rps.pt\"\n",
    "\n",
    "# Ensure the models/yolo directory exists\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "\n",
    "# Copy best.pt to models/yolo with the new name\n",
    "source_path = os.path.join(train_location, \"best.pt\")\n",
    "destination_file = os.path.join(models_dir, new_model_name)\n",
    "\n",
    "if os.path.exists(source_path):\n",
    "    shutil.copy2(source_path, destination_file)\n",
    "    print(f\"Copied: {source_path} â†’ {destination_file}\")\n",
    "else:\n",
    "    print(f\"Error: {source_path} not found!\")\n",
    "\n",
    "# List destination contents\n",
    "print(\"Contents of models/yolo directory:\")\n",
    "os.system(f\"ls {models_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96199ae",
   "metadata": {},
   "source": [
    "### Validate new Trained RPS Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b277a5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model_path = destination_file\n",
    "#print(destination_path)\n",
    "\n",
    "model = YOLO(new_model_path)  # load a trained model\n",
    "\n",
    "# Validate the model\n",
    "metrics = model.val()  # no arguments needed, dataset and settings remembered\n",
    "metrics.box.map  # map50-95\n",
    "metrics.box.map50  # map50\n",
    "metrics.box.map75  # map75\n",
    "metrics.box.maps  # a list contains map50-95 of each category"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cdf5882",
   "metadata": {},
   "source": [
    "### Test Model with some new Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb1990b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import random\n",
    "from IPython.display import display, Image as IPyImage\n",
    "\n",
    "# Define test image location\n",
    "images_location = f\"{dataset_full_path}/test/images\"\n",
    "print(f\"Test images directory: {images_location}\")\n",
    "\n",
    "# Select up to 30 test images\n",
    "test_images = glob.glob(f\"{images_location}/*.jpg\")\n",
    "test_images = random.sample(test_images, min(len(test_images), 30))  # Randomly pick up to 30\n",
    "\n",
    "if not test_images:\n",
    "    print(\"Error: No test images found.\")\n",
    "else:\n",
    "    # Run inference on selected images\n",
    "    results = model.predict(source=test_images, conf=0.25, save=True)\n",
    "\n",
    "    # Get latest prediction folder\n",
    "    predict_folders = glob.glob(f'{HOME}/runs/detect/predict*/')\n",
    "    if predict_folders:\n",
    "        latest_folder = max(predict_folders, key=os.path.getmtime)\n",
    "\n",
    "        # Randomly select up to 10 images from predictions\n",
    "        predicted_images = glob.glob(f'{latest_folder}/*.jpg')\n",
    "        images_to_display = random.sample(predicted_images, min(len(predicted_images), 10))\n",
    "\n",
    "        # Display selected images\n",
    "        for img in images_to_display:\n",
    "            display(IPyImage(filename=img, width=300))\n",
    "    else:\n",
    "        print(\"No prediction results found.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f6c803-acf7-44e6-b468-25aa72c9bb9e",
   "metadata": {},
   "source": [
    "### Export Model to ONNX\n",
    "\n",
    "Often, when deploying computer vision models, you'll need a model format that's both flexible and compatible with multiple platforms.\n",
    "\n",
    "Exporting YOLO11 models to ONNX format streamlines deployment and ensures optimal performance across various environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c27049e-6b33-4403-b576-09834780875b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model paths using existing variables\n",
    "\n",
    "YOLO_Rock_Paper = new_model_path\n",
    "YOLO_Rock_Paper_ONNX = os.path.join(models_dir, f\"yolo-rps.onnx\")\n",
    "\n",
    "# Verify if the model exists before proceeding\n",
    "if not os.path.exists(YOLO_Rock_Paper):\n",
    "    raise FileNotFoundError(f\"Error: Model file {YOLO_Rock_Paper} not found.\")\n",
    "\n",
    "print(f\"Using model: {YOLO_Rock_Paper}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c719f7b-3893-4612-8c73-c552c1a44bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export model to ONNX format\n",
    "if not os.path.exists(YOLO_Rock_Paper_ONNX):  # Avoid re-exporting if already exists\n",
    "    model.export(format=\"onnx\")\n",
    "    print(f\"Exported model to ONNX format at {YOLO_Rock_Paper_ONNX}\")\n",
    "else:\n",
    "    print(f\"ONNX model already exists at {YOLO_Rock_Paper_ONNX}\")\n",
    "\n",
    "# Load ONNX model \n",
    "onnx_model = YOLO(YOLO_Rock_Paper_ONNX)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d893a5fc",
   "metadata": {},
   "source": [
    "### Test Prediction with exported ONNX Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c846c7f-ff84-4351-a5ba-063fa47a55af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define test image path dynamically\n",
    "image_name = \"20220216_221550_jpg.rf.02a071a383151953fcf8671fc7fca3af.jpg\"\n",
    "IMG = os.path.join(destination_path, \"test\", \"images\", image_name)\n",
    "\n",
    "if not os.path.exists(IMG):\n",
    "    raise FileNotFoundError(f\"Error: Test image {IMG} not found.\")\n",
    "\n",
    "print(f\"Using test image: {IMG}\")\n",
    "\n",
    "# Run inference\n",
    "results = onnx_model(IMG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f621683-6549-4329-91b2-50be3c419d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process results\n",
    "for result in results:\n",
    "    print(\"Processing result...\")\n",
    "    if hasattr(result, \"boxes\"):\n",
    "        print(\"Boxes:\", result.boxes)\n",
    "    if hasattr(result, \"masks\"):\n",
    "        print(\"Masks:\", result.masks)\n",
    "    if hasattr(result, \"keypoints\"):\n",
    "        print(\"Keypoints:\", result.keypoints)\n",
    "    if hasattr(result, \"probs\"):\n",
    "        print(\"Probabilities:\", result.probs)\n",
    "    if hasattr(result, \"obb\"):\n",
    "        print(\"Oriented Boxes:\", result.obb)\n",
    "\n",
    "    # Display and optionally save results\n",
    "    result.show()  # Display result\n",
    "    # result.save(filename=os.path.join(destination_dir, \"result.jpg\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
